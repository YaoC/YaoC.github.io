<!doctype html>



  


<html class="theme-next pisces use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,python,概率," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="定义 隐马尔可夫模型（HMM）是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为状态序列（ state sequence ) ；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（ observation sequence ) 。序列的每一个位置又可以看作是一个时刻">
<meta name="keywords" content="机器学习,python,概率">
<meta property="og:type" content="article">
<meta property="og:title" content="隐马尔可夫模型—《统计学习方法》学习笔记">
<meta property="og:url" content="http://yaochg.com/2016/10/18/隐马尔可夫模型—《统计学习方法》学习笔记/index.html">
<meta property="og:site_name" content="YaoC&#39;s Blog">
<meta property="og:description" content="定义 隐马尔可夫模型（HMM）是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为状态序列（ state sequence ) ；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（ observation sequence ) 。序列的每一个位置又可以看作是一个时刻">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://o9w932hp8.bkt.clouddn.com/%E7%8A%B6%E6%80%81%E5%9B%BE%20%281%29.png">
<meta property="og:image" content="http://o9w932hp8.bkt.clouddn.com/%E5%89%8D%E5%90%91%E6%A6%82%E7%8E%87.png">
<meta property="og:image" content="http://o9w932hp8.bkt.clouddn.com/%E5%90%8E%E5%90%91%E6%A6%82%E7%8E%87.png">
<meta property="og:updated_time" content="2016-10-19T07:31:17.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="隐马尔可夫模型—《统计学习方法》学习笔记">
<meta name="twitter:description" content="定义 隐马尔可夫模型（HMM）是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为状态序列（ state sequence ) ；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（ observation sequence ) 。序列的每一个位置又可以看作是一个时刻">
<meta name="twitter:image" content="http://o9w932hp8.bkt.clouddn.com/%E7%8A%B6%E6%80%81%E5%9B%BE%20%281%29.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yaochg.com/2016/10/18/隐马尔可夫模型—《统计学习方法》学习笔记/"/>

  <title> 隐马尔可夫模型—《统计学习方法》学习笔记 | YaoC's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">YaoC's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                隐马尔可夫模型—《统计学习方法》学习笔记
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-18T12:04:33+08:00" content="2016-10-18">
              2016-10-18
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/18/隐马尔可夫模型—《统计学习方法》学习笔记/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/18/隐马尔可夫模型—《统计学习方法》学习笔记/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/18/隐马尔可夫模型—《统计学习方法》学习笔记/" class="leancloud_visitors" data-flag-title="隐马尔可夫模型—《统计学习方法》学习笔记">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><blockquote>
<p><strong>隐马尔可夫模型（HMM）</strong>是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为状态序列（ state sequence ) ；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（ observation sequence ) 。序列的每一个位置又可以看作是一个时刻．</p>
</blockquote>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>$$HMM:\lambda=(A,B,\pi)$$</p>
<ul>
<li>A： 状态转移概率分布</li>
<li>B： 观测概率分布</li>
<li>π： 初始概率分布</li>
</ul>
<h2 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h2><p>假设有4个盒子，每个盒子里都装有红白两种颜色的球，盒子里的红白球数由下表列出：</p>
<table>
<thead>
<tr>
<th style="text-align:center">盒子</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">红球数</td>
<td style="text-align:center">5</td>
<td style="text-align:center">3</td>
<td style="text-align:center">6</td>
<td style="text-align:center">8</td>
</tr>
<tr>
<td style="text-align:center">白球数</td>
<td style="text-align:center">5</td>
<td style="text-align:center">7</td>
<td style="text-align:center">4</td>
<td style="text-align:center">2</td>
</tr>
</tbody>
</table>
<p>按照下面的方法抽球，产生一个球的颜色的观测序列：开始，从 4 个盒子里以等概率随机选取 1 个盒子，从这个盒子里随机抽出 1 个球，记录其颜色后，放回；然后，从当前盒子随机转移到下一个盒子，规则是：如果当前盒子是盒子 1 , 那么下一盒子一定是盒子 2 ，如果当前是盒子 2 或 3 ，那么分别以概率0.4 和0.6 转移到左边或右边的盒子，如果当前是盒子 4 ，那么各以 0.5 的概率停留在盒子 4 或转移到盒子 3 ；确定转移的盒子后，再从这个盒子里随机抽出 1 个球，记录其颜色，放回；如此下去，重复进行 5 次，得到一个球的颜色的观测序列:<br>$$O={红，红，白，白，红}$$</p>
<ul>
<li>状态集合： $$Q={盒子1，盒子2，盒子3，盒子4}$$</li>
<li>观测集合: $$V={红色，白色}$$</li>
<li>状态转换图：<br><img src="http://o9w932hp8.bkt.clouddn.com/%E7%8A%B6%E6%80%81%E5%9B%BE%20%281%29.png" alt="状态转换图"></li>
<li>初始概率分布：$$\pi=(0.25，0.25，0.25，0.25)^T$$</li>
</ul>
<p>根据状态转换图得到，</p>
<ul>
<li><p>状态转移分布：<br>$$A=\begin{bmatrix} 0 &amp; 1 &amp;0&amp;0\ 0.4&amp; 0&amp;0.6&amp; 0\0&amp;0.4&amp;0&amp;0.6\0&amp;0&amp;0.5&amp;0.5\end{bmatrix}\quad$$</p>
</li>
<li><p>观测概率分布：<br>$$B=\begin{bmatrix} 0.5 &amp; 0.5 \ 0.3&amp; 0.7\0.6&amp;0.4\0.8&amp;0.2 \end{bmatrix}\quad$$</p>
</li>
</ul>
<h2 id="HMM的三个基本问题"><a href="#HMM的三个基本问题" class="headerlink" title="HMM的三个基本问题"></a>HMM的三个基本问题</h2><ol>
<li>概率计算问题：$$(\lambda,O)\to P(O|\lambda)$$</li>
<li>学习问题：$$(P(O|\lambda),O)\to \lambda$$</li>
<li>预测问题：$$(\lambda,O)\to P(I|O)$$</li>
</ol>
<h3 id="概率计算"><a href="#概率计算" class="headerlink" title="概率计算"></a>概率计算</h3><h4 id="问题建模"><a href="#问题建模" class="headerlink" title="问题建模"></a>问题建模</h4><p>给定HMM模型 \(\lambda = (A,B,\pi)\) 和 观测序列 \(O=(o_1,o_2,…,o_T)\) ，计算观测序列 \(O\) 出现的概率 \(P(O|\lambda)\)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate.py</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始概率分布</span></span><br><span class="line">pi = np.array((<span class="number">0.25</span>,<span class="number">0.25</span>,<span class="number">0.25</span>,<span class="number">0.25</span>))</span><br><span class="line"><span class="comment"># 状态转移分布</span></span><br><span class="line">A = np.array(((<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>),(<span class="number">0.4</span>,<span class="number">0</span>,<span class="number">0.6</span>,<span class="number">0</span>),(<span class="number">0</span>,<span class="number">0.4</span>,<span class="number">0</span>,<span class="number">0.6</span>),(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">0.5</span>)))</span><br><span class="line"><span class="comment"># 观测概率分布</span></span><br><span class="line">B = np.array(((<span class="number">0.5</span>,<span class="number">0.5</span>),(<span class="number">0.3</span>,<span class="number">0.7</span>),(<span class="number">0.6</span>,<span class="number">0.4</span>),(<span class="number">0.8</span>,<span class="number">0.2</span>)))</span><br><span class="line">M = <span class="number">4</span> <span class="comment">#状态集大小</span></span><br><span class="line">N = <span class="number">2</span> <span class="comment">#观测集大小</span></span><br></pre></td></tr></table></figure></p>
<h4 id="1-直接计算法（蛮力法）"><a href="#1-直接计算法（蛮力法）" class="headerlink" title="1. 直接计算法（蛮力法）"></a>1. 直接计算法（蛮力法）</h4><ol>
<li>列举出所有可能出现的长度为T的状态序列 \(I=(i_1,i_2,…,i_T)\)</li>
<li>计算在当前模型下出现的概率 \(P(I|\lambda)=\pi_{i_{1}} a_{i_{1}i_{2}} a_{i_{2} i_{3}}…a_{i_{T-1} i_{T}}\)</li>
<li>计算在某个状态序列 \(I=(i_1,i_2,…,i_T)\) 下，观测序列 \(O=(o_1,o_2,…,o_T)\) 出现的概率 \(P(O|I,\lambda)=b_{i_1o_1}b_{i_2o_2}…b_{i_To_T}\)</li>
<li>计算在当前模型下O与I同时出现的联合概率 \(P(O,I|\lambda)=P(O|I,\lambda)P(I|\lambda)\)</li>
<li>对所有的状态序列I求和， \(P(O|\lambda) = \sum_{I}{(O,I|\lambda)}\)</li>
</ol>
<p><strong>代码实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">使用蛮力法直接计算：给定模型λ=(A,B,pi)，观测序列O出现的概率P(O|λ)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">from</span> generate <span class="keyword">import</span> A,B,pi,M</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> product</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列举所有可能的长度为seqLength的状态序列</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateSeq</span><span class="params">(seqLength)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> [seq <span class="keyword">for</span> seq <span class="keyword">in</span> product(range(M),repeat=seqLength)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 状态序列I的概率P(I|λ)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probI</span><span class="params">(I)</span>:</span></span><br><span class="line">	prob = pi[I[<span class="number">0</span>]]</span><br><span class="line">	<span class="keyword">for</span> x <span class="keyword">in</span> xrange(len(I)<span class="number">-1</span>):</span><br><span class="line">		prob *= A[I[x],I[x+<span class="number">1</span>]]</span><br><span class="line">	<span class="keyword">return</span> prob</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对固定的状态序列I，观测序列O的概率P(O|I,λ)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probOAtI</span><span class="params">(I,O)</span>:</span></span><br><span class="line">	prob = <span class="number">1</span></span><br><span class="line">	<span class="keyword">for</span> x <span class="keyword">in</span> xrange(len(I)):</span><br><span class="line">		prob *= B[I[x],O[x]]</span><br><span class="line">	<span class="keyword">return</span> prob</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算O和I同时出现的联合概率P(O,I|λ),然后对所有可能的状态序列I求和，得到观测序列O的概率P(O|λ)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probO</span><span class="params">(o)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> sum([probI(i)*probOAtI(i,o) <span class="keyword">for</span> i <span class="keyword">in</span> generateSeq(len(o))])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">	o = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]	<span class="comment">#&#123;红，红，白，白，红&#125;</span></span><br><span class="line">	<span class="keyword">print</span> probO(o)		</span><br><span class="line">	<span class="comment"># 可以测试一下所有观测序列O的概率总和是否为1</span></span><br><span class="line">	<span class="keyword">print</span> sum([ probO(x) <span class="keyword">for</span> x <span class="keyword">in</span> product([<span class="number">0</span>,<span class="number">1</span>],repeat=len(o)) ])</span><br></pre></td></tr></table></figure></p>
<h4 id="2-前向算法"><a href="#2-前向算法" class="headerlink" title="2. 前向算法"></a>2. 前向算法</h4><p>动态规划算法，定义<strong>前向概率</strong>：到t时刻部分观测序列为 \(o_1,o_2,…,o_t\) 且（t时刻）态为 \(q_i\) 的概率。记作：<br>$$\alpha_t(i)=P(o_1,o_2,…,o_t,i_t=q<em>i|\lambda)$$<br>容易看出，\(P(O|\lambda)=\sum</em>{i=1}^{N}\alpha_T(i)\)</p>
<p><strong>求解方法：</strong></p>
<ol>
<li>初值$$\alpha_1(i)=\pi<em>ib</em>{io_1}$$</li>
<li>递推公式 $$\alpha<em>{t+1}(i)=[\sum</em>{j=1}^{N}\alpha<em>t(j)a</em>{ji}]b<em>{io</em>{t+1}}$$</li>
<li>终止 $$P(O|\lambda)=\sum_{i=1}^{N}\alpha_T(i)$$</li>
</ol>
<p>前向概率 \(\alpha_3(1)\) 图解<br><img src="http://o9w932hp8.bkt.clouddn.com/%E5%89%8D%E5%90%91%E6%A6%82%E7%8E%87.png" alt="前向概率"></p>
<p><strong>代码实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">使用前向算法计算：给定模型λ=(A,B,pi)，观测序列O出现的概率P(O|λ)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> generate <span class="keyword">import</span> A,B,pi,M</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> product</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向概率alpha[t,i]：时刻t部分观测序列为O(t)=&#123;01,02,...,ot&#125;，且状态为qi的概率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAlpha</span><span class="params">(o)</span>:</span></span><br><span class="line">    T = len(o)</span><br><span class="line">    alpha = np.zeros([T,M])</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(M):</span><br><span class="line">        alpha[<span class="number">0</span>,i] = pi[i]*B[i,o[<span class="number">0</span>]]</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> xrange(<span class="number">1</span>,T):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(M):</span><br><span class="line">            alpha[x,i] = sum([alpha[x<span class="number">-1</span>,j]*A[j,i] <span class="keyword">for</span> j <span class="keyword">in</span> xrange(M)])*B[i,o[x]]</span><br><span class="line">    <span class="keyword">return</span> alpha</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probO</span><span class="params">(t,o)</span>:</span></span><br><span class="line">    alpha = getAlpha(o)</span><br><span class="line">    <span class="keyword">return</span> sum(alpha[t])</span><br><span class="line">           </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    o = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]	<span class="comment">#&#123;红，红，白，白，红&#125;</span></span><br><span class="line">    <span class="keyword">print</span> probO(len(o)<span class="number">-1</span>,o)</span><br><span class="line">    <span class="comment"># 可以测试一下所有观测序列O的概率总和是否为1</span></span><br><span class="line">    <span class="keyword">print</span> sum([ probO(len(o)<span class="number">-1</span>,x) <span class="keyword">for</span> x <span class="keyword">in</span> product([<span class="number">0</span>,<span class="number">1</span>],repeat=len(o)) ])</span><br></pre></td></tr></table></figure></p>
<h4 id="3-后向算法"><a href="#3-后向算法" class="headerlink" title="3. 后向算法"></a>3. 后向算法</h4><p>定义<strong>后向概率</strong>：在t时刻状态为 \(q_i\) 的条件下，从 t+1 到 T 的部分观测序列为 \(o_{t+1},o_{t+2},…,o_T\) 的概率。记作：<br>$$\beta<em>t(i)=P(o</em>{t+1},o_{t+2},…,o_T|i_t=q_i,\lambda)$$<br>通过递推可求出 \(P(O|\lambda)\)<br><strong>求解方法</strong></p>
<ol>
<li>初值 $$\beta_T(i)=1$$</li>
<li>递推公式 $$\beta<em>t(i)=\sum</em>{j=1}^{N}a<em>{ij}b</em>{jo<em>{t+1}}\beta</em>{t+1}(j)$$</li>
<li>终止 $$P(O|\lambda)=\sum_{i=1}^{N}\pi<em>ib</em>{io_1}\beta_1(i)$$</li>
</ol>
<p>后向概率 \(\beta_1(3)\) 图解<br><img src="http://o9w932hp8.bkt.clouddn.com/%E5%90%8E%E5%90%91%E6%A6%82%E7%8E%87.png" alt="后向概率"></p>
<p><strong>代码实现</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">使用后向算法计算：给定模型λ=(A,B,pi)，观测序列O出现的概率P(O|λ)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> generate <span class="keyword">import</span> A,B,pi,M</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> product</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后向概率beta[t,i]：时刻t状态为qi的条件下，</span></span><br><span class="line"><span class="comment"># t+1时刻到T时刻部分观测序列为O(t)=&#123;0t+1,0t+2,...,oT&#125;的概率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getBeta</span><span class="params">(o)</span>:</span></span><br><span class="line">    T = len(o)</span><br><span class="line">    beta = np.zeros([T,M])</span><br><span class="line">    beta[T<span class="number">-1</span>] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> xrange(<span class="number">2</span>,T+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> xrange(M):</span><br><span class="line">            beta[T-x,i] = sum([A[i,j]*B[j,o[T-x+<span class="number">1</span>]]*beta[T-x+<span class="number">1</span>,j] <span class="keyword">for</span> j <span class="keyword">in</span> xrange(M)])</span><br><span class="line">    <span class="keyword">return</span> beta</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probO</span><span class="params">(o)</span>:</span></span><br><span class="line">    beta = getBeta(o)    </span><br><span class="line">    <span class="keyword">return</span> sum([pi[i]*B[i,o[<span class="number">0</span>]]*beta[<span class="number">0</span>,i] <span class="keyword">for</span> i <span class="keyword">in</span> xrange(M)])        </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    o = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]	<span class="comment">#&#123;红，红，白，白，红&#125;</span></span><br><span class="line">    <span class="keyword">print</span> probO(o)</span><br><span class="line">    <span class="comment"># 可以测试一下所有观测序列O的概率总和是否为1</span></span><br><span class="line">    <span class="keyword">print</span> sum([ probO(x) <span class="keyword">for</span> x <span class="keyword">in</span> product([<span class="number">0</span>,<span class="number">1</span>],repeat=len(o)) ])</span><br></pre></td></tr></table></figure></p>
<ul>
<li>给定模型 \(\lambda\) 和观测 O，<strong>在时刻 t 处于状态 \(q_i\) 的概率</strong>：</li>
</ul>
<p>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle \gamma_t(i)=P(i_t=q_i|O,\lambda)=\frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)}=\frac{\alpha_t(i)\beta<em>t(i)}{\sum</em>{j=1}^N\alpha_t(j)\beta_t(j)}\<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$</p>
<ul>
<li>给定模型 \(\lambda\) 和观测 O，<strong>在时刻 t 处于状态 \(q_i\) 且在时刻 t+1 处于状态 \(q_j\) 的概率</strong>:<br>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle \zeta_t(i,j)&amp;=\frac{P(i_t=q<em>i,i</em>{t+1}=q_j,O|\lambda)}{P(O|\lambda)} \<br>\displaystyle \newline<br>\displaystyle &amp;=\frac{P(i_t=q<em>i,i</em>{t+1}=q<em>j,O|\lambda)}{\sum</em>{i=1}^N\sum_{j=1}^N P(i_t=q<em>i,i</em>{t+1}=q_j,O|\lambda)} \<br>\displaystyle \newline<br>\displaystyle 由于\qquad &amp;P(i_t=q<em>i,i</em>{t+1}=q_j,O|\lambda)=\alpha<em>t(i)a</em>{ij}b<em>{jo</em>{t+1}}\beta_{t+1}(j)  \<br>\displaystyle \newline<br>\displaystyle  \zeta_t(i,j)&amp;=\frac{P(i_t=q<em>i,i</em>{t+1}=q_j,O|\lambda)}{P(O|\lambda)} \<br>\displaystyle \newline<br>\displaystyle &amp;=\frac{\alpha<em>t(i)a</em>{ij}b<em>{jo</em>{t+1}}\beta<em>{t+1}(j)}{\sum</em>{i=1}^N\sum_{j=1}^N \alpha<em>t(i)a</em>{ij}b<em>{jo</em>{t+1}}\beta_{t+1}(j)}<br>\displaystyle \newline<br>\displaystyle \newline<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$</li>
</ul>
<p>将 \(\gamma_t(i)\) 和 \(\zeta_t(i,j)\) 对各个时刻 t 求和，得到：</p>
<ul>
<li>在观测 O 下状态 i 出现的期望值 $$\sum_{t=1}^{T}\gamma_t(i)$$</li>
<li>在观测 O 下由状态 i 转移的期望值 $$\sum_{t=1}^{T-1}\gamma_t(i)$$</li>
<li>在观测 O 下由状态 i 转移到状态 j 的期望值 $$\sum_{t=1}^{T-1}\zeta_t(i,j)$$</li>
</ul>
<h3 id="学习问题"><a href="#学习问题" class="headerlink" title="学习问题"></a>学习问题</h3><p>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle (P(O|\lambda),O)\to \lambda \<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$</p>
<ul>
<li>有<strong>观测序列</strong>和对应的<strong>状态序列</strong> —— <code>监督学习</code></li>
<li>只有<strong>观测序列</strong> —— <code>非监督学习</code> （EM算法）</li>
</ul>
<h4 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h4><p>使用<code>极大似然法</code>估计 \(A,B,\lambda\)<br><strong>训练集</strong>：<br>$${(O_1,I_1),(O_2,I_2),…,(O_S,I_S)}$$<br><strong>估计：</strong></p>
<ol>
<li>转移概率 \(a_{ij}\) 的估计（ \(A_{ij}\) ：时刻 t 处于状态i，时刻 t+1 处于状态j的频数）：<br>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle \hat{a}<em>{ij}=\frac{A</em>{ij}}{\sum^N<em>{j=1}A</em>{ij}},\qquad  i=1,2,…,N;j=1,2,…,N\<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$ </li>
<li>观测概率 \(b_{jk}\) 的估计（\(B_{jk}\)： 状态为 j ，观测为 k 的频数）：<br>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle \hat{b}<em>{jk}=\frac{B</em>{jk}}{\sum^M<em>{k=1}B</em>{jk}},\qquad j=1,2,…,N;k=1,2,…,M\<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$ </li>
<li>初始状态概率 \(\pi_i\) 的估计 \(\hat{\pi}_i\) 为 S 个样本中初始状态为 \(q_i\) 的频率 </li>
</ol>
<blockquote>
<p>监督学习需要使用训练数据，人工标注训练数据代价较高，故有时会使用非监督学习</p>
</blockquote>
<h4 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h4><p>使用 <code>Baum-Welch</code> 算法<br><strong>训练集</strong>：<br>$${O_1,O_2,…,O_S}$$<br>虽然没有状态数据，但HMM模型事实上是一个含有隐变量的概率模型<br>$$P(O|I)=\sum_I P(O|I,\lambda)P(I|\lambda)$$<br>它的参数学习可由 <a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" target="_blank" rel="noopener">EM算法</a> 实现：</p>
<ol>
<li>确定完全数据的对数似然函数：<br>$$\log P(O,I|\lambda)$$</li>
<li>EM算法的 E 步：求 Q 函数 \(Q(\lambda,\bar{\lambda})\) ，\(\bar{\lambda}\) ： HMM模型参数的当前估计值， \(\lambda\) ：要极大化的HMM模型参数<br>$$Q(\lambda,\bar{\lambda})=\sum<em>I [\log P(O,I|\lambda)]P(O,I|\bar{\lambda})$$<br>$$P(O,I|\lambda)=\pi</em>{i<em>1}b</em>{i_1o<em>1}a</em>{i_1i<em>2}b</em>{i_2o<em>2}…a</em>{i_{T-1}i<em>T}b</em>{i_To_T}$$<br>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle 于是\qquad Q(\lambda,\bar{\lambda})&amp;=\sum<em>I (\log \pi</em>{i<em>1}b</em>{i_1o<em>1}a</em>{i_1i<em>2}b</em>{i_2o<em>2}…a</em>{i_{T-1}i<em>T}b</em>{i_To_T})P(O,I|\bar{\lambda})\<br>\displaystyle \newline<br>\displaystyle &amp;= \sum<em>I (\log \pi</em>{i_1})P(O,I|\bar{\lambda})+\sum<em>I (\log a</em>{i_1i<em>2}a</em>{i_2i<em>3}…a</em>{i_{T-1}i_T})P(O,I|\bar{\lambda}) \<br>\displaystyle \newline<br>\displaystyle &amp;\qquad +\sum<em>I (\log b</em>{i_1o<em>1}b</em>{i_2o<em>2}…b</em>{i_To_T})P(O,I|\bar{\lambda}) \<br>\displaystyle \newline<br>\displaystyle &amp;=\sum<em>I (\log \pi</em>{i_1})P(O,I|\bar{\lambda})+\sum<em>I [\sum</em>{t=1}^{T-1}\log a_{i<em>ti</em>{t+1}}]P(O,I|\bar{\lambda}) \<br>\displaystyle \newline<br>\displaystyle &amp;\qquad +\sum<em>I [\sum</em>{t=1}^T\log b_{i_to_t}]P(O,I|\bar{\lambda})<br>\displaystyle \newline<br>\displaystyle \newline<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$</li>
<li>EM算法的M步：极大化Q函数 \(Q(\lambda,\bar{\lambda})\) 求模型参数 \(A,B,\pi\)<br>对 Q 函数的三项分别极大化：<br>使用拉格朗日乘子法可得</li>
</ol>
<p>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle \pi_i=\frac{P(O,i<em>1=i|\bar{\lambda})}{P(O|\bar{\lambda})} \<br>\displaystyle \newline<br>\displaystyle a</em>{ij}=\frac{\sum_{t=1}^{T-1}P(O,i<em>t=t,i</em>{t+1}=j|\bar{\lambda})}{\sum_{t=1}^{T-1}P(O,i<em>t=i|\bar{\lambda})} \<br>\displaystyle \newline<br>\displaystyle b</em>{jk}=\frac{\sum_{t=1}^{T}P(O,i_t=j|\bar{\lambda})I(o_t=v_k)}{P(O,i_t=j|\bar{\lambda})} \<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$<br>\(\qquad \qquad 用\gamma_t(i)\) 和 \(\zeta_t(i,j)\) 表示为<br>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle \pi i=\gamma<em>1(i) \<br>\displaystyle \newline<br>\displaystyle a</em>{ij}=\frac{\sum_{t=1}^{T-1}\zeta<em>t(i,j)}{\sum</em>{t=1}^{T-1}\gamma<em>t(i)} \<br>\displaystyle \newline<br>\displaystyle b</em>{jk}=\frac{\sum_{t=1,o_t=v_k}^{T}\gamma<em>t(i)}{\sum</em>{t=1}^{T}\gamma_t(j)} \<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$</p>
<p><strong>具体实现</strong></p>
<ol>
<li><strong>初始化</strong> ：对 n=0 ，选取 \({a_{ij}}^{(0)}\) ，\({b_{jk}}^{(0)}\) ，\({\pi_{i}}^{(0)}\) ， 得到模型 \({\lambda}^{(0)}=({A}^{(0)},{B}^{(0)},{\pi}^{(0)})\)</li>
<li><strong>递推计算</strong> \({a_{ij}}^{(n)}\) ，\({b_{jk}}^{(n)}\) ，\({\pi_{i}}^{(n)}\)  ， 得到模型 \({\lambda}^{(n)}=({A}^{(n)},{B}^{(n)},{\pi}^{(n+1)})\)</li>
<li><strong>终止</strong>，得到最终模型 \({\lambda}^{(n+1)}=({A}^{(n+1)},{B}^{(n+1)},{\pi}^{(n+1)})\)</li>
</ol>
<h3 id="预测问题"><a href="#预测问题" class="headerlink" title="预测问题"></a>预测问题</h3><p>HMM预测问题一般有两种算法：<code>近似算法</code> 和 <code>维特比算法</code></p>
<h4 id="近似算法"><a href="#近似算法" class="headerlink" title="近似算法"></a>近似算法</h4><p><strong>思想</strong>：在每个时刻 t 选择在该时刻最有可能出现的状态 \(i^*_t\)，从而得到一个状态序列 \( I^*=(i_1^*,i_2^*,…,i_T^*) \)作为预测结果<br>给定隐马尔可夫模型观测 \(\lambda\) 和 观测序列 O ，在 t 时刻处于状态 \(q_i\) 的概率\(\gamma_t(i)\)是<br>$$\gamma_t(i)=P(i_t=q_i|O,\lambda)=\frac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)}=\frac{\alpha_t(i)\beta<em>t(i)}{\sum</em>{j=1}^N\alpha_t(j)\beta_t(j)}$$<br>在每一时刻 t 最有可能的状态 \(i_t^<em>\) 是<br>$$i_t^</em>= \arg \max_{1\leqslant i \leqslant N} [\gamma_t(i)] \qquad t=1,2,…,T$$</p>
<h4 id="维特比算法"><a href="#维特比算法" class="headerlink" title="维特比算法"></a>维特比算法</h4><p>实际是用动态规划求概率最大路径（状态序列）<br><strong>定义</strong></p>
<ul>
<li><p>在时刻 t 的所有单个路径 \((i_1,i_2,…,i_t)\) 中概率最大值为<br>$$<br>\begin{equation<em>}<br>\begin{array}{l}<br>\displaystyle \newline<br>\displaystyle \delta<em>t(i)&amp;=\max</em>{i_1,i<em>2,…,i</em>{t-1}} P(i<em>t=i,i</em>{t-1},…,i_1,o_t,…,o<em>1|\lambda)\<br>\displaystyle \newline<br>\displaystyle \delta</em>{t+1}(i)&amp;=\max_{i_1,i_2,…,i<em>t} P(i</em>{t+1}=i,i_{t},…,i<em>1,o</em>{t+1},…,o<em>1|\lambda) \<br>\displaystyle \newline<br>\displaystyle &amp;=\max</em>{1\leqslant j \leqslant N}[\delta<em>t(j)a</em>{ji}]b<em>{io</em>{t+1}}\<br>\displaystyle \newline<br>\displaystyle \newline<br>\end{array}<br>\end{equation</em>}<br>$$</p>
</li>
<li><p>在时刻 t 状态为 i 的所有单个路径 \((i_1,i_2,…,i_t)\)  中概率最大的路径的第 t-1 个结点为<br>$$\psi<em>t(i)=\arg \max</em>{1\leqslant j \leqslant N}[\delta<em>{t-1}(j)a</em>{ji}],\qquad i=1,2,…,N$$</p>
</li>
</ul>
<p><strong>维特比算法</strong></p>
<ol>
<li><strong>初始化</strong><br>$$\delta_1(i)=\pi<em>ib</em>{io_1},\qquad i=1,2,…,N$$<br>$$\psi_1(i)=0,\qquad i=1,2,…,N$$</li>
<li><strong>递推</strong>，对 t=2,3,…,T<br>$$\delta<em>t(i)=\max</em>{1\leqslant j \leqslant N}[\delta<em>{t-1}(j)a</em>{ji}]b_{io_t},\qquad i=1,2,…,N$$<br>$$\psi<em>t(i)=\arg \max</em>{1\leqslant j \leqslant N}[\delta<em>{t-1}(j)a</em>{ji}],\qquad i=1,2,…,N$$</li>
<li><strong>终止</strong><br>$$P^<em>=\max_{1\leqslant i \leqslant N}\delta_T(i)$$<br>$$i_T^</em>=\arg \max_{1\leqslant i \leqslant N}[\delta_T(i)]$$</li>
<li><strong>回溯最优路径</strong> ， 对 t=T-1,T-2,…,1<br>$$i<em>t^*=\psi</em>{t+1}(i_{t+1}^<em>)$$<br>得到 \( I^\</em>=(i_1^*,i_2^*,…,i_T^*) \)</li>
</ol>
<p><br><br><br></p>

      
    </div>

    <div>
      
        
      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div></div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/images/wechat.jpg" alt="Cheng Yao WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/images/alipay.jpg" alt="Cheng Yao Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag">#机器学习</a>
          
            <a href="/tags/python/" rel="tag">#python</a>
          
            <a href="/tags/概率/" rel="tag">#概率</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/10/07/使用hadoop命令运行程序（hadoop-2-7-3）/" rel="next" title="使用hadoop命令运行程序（hadoop 2.7.3）">
                <i class="fa fa-chevron-left"></i> 使用hadoop命令运行程序（hadoop 2.7.3）
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/12/06/Hadoop-二次排序/" rel="prev" title="Hadoop 二次排序">
                Hadoop 二次排序 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          

  <p>热评文章</p>
  <div class="ds-top-threads" data-range="weekly" data-num-items="4"></div>


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/10/18/隐马尔可夫模型—《统计学习方法》学习笔记/"
           data-title="隐马尔可夫模型—《统计学习方法》学习笔记" data-url="http://yaochg.com/2016/10/18/隐马尔可夫模型—《统计学习方法》学习笔记/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Cheng Yao" />
          <p class="site-author-name" itemprop="name">Cheng Yao</p>
          <p class="site-description motion-element" itemprop="description">You'll never walk alone</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">5</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/YaoC" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:chengyao09@hotmail.com" target="_blank" title="邮箱">
                  
                    <i class="fa fa-fw fa-envelope"></i>
                  
                  邮箱
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/648470867" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/Cyao" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#定义"><span class="nav-number">1.</span> <span class="nav-text"><a href="#&#x5B9A;&#x4E49;" class="headerlink" title="&#x5B9A;&#x4E49;"></a>&#x5B9A;&#x4E49;</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型"><span class="nav-number">2.</span> <span class="nav-text"><a href="#&#x6A21;&#x578B;" class="headerlink" title="&#x6A21;&#x578B;"></a>&#x6A21;&#x578B;</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#举例"><span class="nav-number">3.</span> <span class="nav-text"><a href="#&#x4E3E;&#x4F8B;" class="headerlink" title="&#x4E3E;&#x4F8B;"></a>&#x4E3E;&#x4F8B;</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HMM的三个基本问题"><span class="nav-number">4.</span> <span class="nav-text"><a href="#HMM&#x7684;&#x4E09;&#x4E2A;&#x57FA;&#x672C;&#x95EE;&#x9898;" class="headerlink" title="HMM&#x7684;&#x4E09;&#x4E2A;&#x57FA;&#x672C;&#x95EE;&#x9898;"></a>HMM&#x7684;&#x4E09;&#x4E2A;&#x57FA;&#x672C;&#x95EE;&#x9898;</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概率计算"><span class="nav-number">4.1.</span> <span class="nav-text"><a href="#&#x6982;&#x7387;&#x8BA1;&#x7B97;" class="headerlink" title="&#x6982;&#x7387;&#x8BA1;&#x7B97;"></a>&#x6982;&#x7387;&#x8BA1;&#x7B97;</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#问题建模"><span class="nav-number">4.1.1.</span> <span class="nav-text"><a href="#&#x95EE;&#x9898;&#x5EFA;&#x6A21;" class="headerlink" title="&#x95EE;&#x9898;&#x5EFA;&#x6A21;"></a>&#x95EE;&#x9898;&#x5EFA;&#x6A21;</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-直接计算法（蛮力法）"><span class="nav-number">4.1.2.</span> <span class="nav-text"><a href="#1-&#x76F4;&#x63A5;&#x8BA1;&#x7B97;&#x6CD5;&#xFF08;&#x86EE;&#x529B;&#x6CD5;&#xFF09;" class="headerlink" title="1. &#x76F4;&#x63A5;&#x8BA1;&#x7B97;&#x6CD5;&#xFF08;&#x86EE;&#x529B;&#x6CD5;&#xFF09;"></a>1. &#x76F4;&#x63A5;&#x8BA1;&#x7B97;&#x6CD5;&#xFF08;&#x86EE;&#x529B;&#x6CD5;&#xFF09;</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-前向算法"><span class="nav-number">4.1.3.</span> <span class="nav-text"><a href="#2-&#x524D;&#x5411;&#x7B97;&#x6CD5;" class="headerlink" title="2. &#x524D;&#x5411;&#x7B97;&#x6CD5;"></a>2. &#x524D;&#x5411;&#x7B97;&#x6CD5;</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-后向算法"><span class="nav-number">4.1.4.</span> <span class="nav-text"><a href="#3-&#x540E;&#x5411;&#x7B97;&#x6CD5;" class="headerlink" title="3. &#x540E;&#x5411;&#x7B97;&#x6CD5;"></a>3. &#x540E;&#x5411;&#x7B97;&#x6CD5;</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#学习问题"><span class="nav-number">4.2.</span> <span class="nav-text"><a href="#&#x5B66;&#x4E60;&#x95EE;&#x9898;" class="headerlink" title="&#x5B66;&#x4E60;&#x95EE;&#x9898;"></a>&#x5B66;&#x4E60;&#x95EE;&#x9898;</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#监督学习"><span class="nav-number">4.2.1.</span> <span class="nav-text"><a href="#&#x76D1;&#x7763;&#x5B66;&#x4E60;" class="headerlink" title="&#x76D1;&#x7763;&#x5B66;&#x4E60;"></a>&#x76D1;&#x7763;&#x5B66;&#x4E60;</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#非监督学习"><span class="nav-number">4.2.2.</span> <span class="nav-text"><a href="#&#x975E;&#x76D1;&#x7763;&#x5B66;&#x4E60;" class="headerlink" title="&#x975E;&#x76D1;&#x7763;&#x5B66;&#x4E60;"></a>&#x975E;&#x76D1;&#x7763;&#x5B66;&#x4E60;</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预测问题"><span class="nav-number">4.3.</span> <span class="nav-text"><a href="#&#x9884;&#x6D4B;&#x95EE;&#x9898;" class="headerlink" title="&#x9884;&#x6D4B;&#x95EE;&#x9898;"></a>&#x9884;&#x6D4B;&#x95EE;&#x9898;</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#近似算法"><span class="nav-number">4.3.1.</span> <span class="nav-text"><a href="#&#x8FD1;&#x4F3C;&#x7B97;&#x6CD5;" class="headerlink" title="&#x8FD1;&#x4F3C;&#x7B97;&#x6CD5;"></a>&#x8FD1;&#x4F3C;&#x7B97;&#x6CD5;</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#维特比算法"><span class="nav-number">4.3.2.</span> <span class="nav-text"><a href="#&#x7EF4;&#x7279;&#x6BD4;&#x7B97;&#x6CD5;" class="headerlink" title="&#x7EF4;&#x7279;&#x6BD4;&#x7B97;&#x6CD5;"></a>&#x7EF4;&#x7279;&#x6BD4;&#x7B97;&#x6CD5;</span></a></li></ol></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng Yao</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.0.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"yaochg"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  
  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("pm4lzO5bgtSm2HH18FqSn9p8-gzGzoHsz", "jljPgaSVoR8JHWTjMNc5VKi4");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

</body>
</html>
